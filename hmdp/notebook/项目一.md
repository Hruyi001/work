# 1. 两级登录拦截器 + ThreadLocal
### 1.1 两级登录拦截器
#### 1.1.1 一级拦截器(对所有请求进行拦截处理)
1. 用户请求携带token，从中获取到token
2. 以token作为key到缓存中查询用户的登录信息，如果缓存没命中，就到mysql库中查询
3. 将用户信息保存到ThreadLocal中（如果用户未登录，ThreadLocal中保存的是一个空对象）
4. 刷新token的有效期
5. 放行请求，交给二级拦截器
#### 1.1.2 二级拦截器（除了登录页面、验证码页面，首页不拦截，拦截处理需要登录的页面）
1. 从ThreadLocal中获取用户信息
2. 如果用户信息为空，说明用户未登录，进行拦截；否则，放行
### 1.2 ThreadLocal 
[见javaguide的ThreadLocal讲解](https://javaguide.cn/java/concurrent/java-concurrent-questions-03.html#%E5%A6%82%E4%BD%95%E8%B7%A8%E7%BA%BF%E7%A8%8B%E4%BC%A0%E9%80%92-threadlocal-%E7%9A%84%E5%80%BC)

# 2. Cannal实现缓存和数据库最终一致性(最终一致性)
## 2.1 Cannal实现缓存和数据库最终一致性核心流程
1. 开启Cannal服务，Cannal会伪装成Mysql的从节点，获取mysql数据库（master节点）的binlog文件
2. Cannal服务端解析binlog文件，将解析后的数据发送给客户端
3. 客户端获取服务端发送的数据后，更新redis缓存

## 2.2 cannal的高可用机制
* cannal宕机：cannal宕机后再次启动，cannal会将宕机过程中的mysql数据，同步给客户端
* 客户端宕机：cannal会将数据保存到内存中，等待客户端再次连接后，将数据同步给客户端
* 消息队列：引入MQ，实现一部解耦、流量削峰，加快数据同步速度
  
# 2(1) zookeeper的强一致性方案

# 3. 缓存穿透、缓存击穿、缓存雪崩
### 3.1 缓存穿透解决方式：布隆过滤器
使用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一定不存在的数据会被这个bitmap 拦截掉，从而避免了对底层存储系统的查询压力。
#### 3.1.0 布隆过滤器原理
根据 key 值计算出它的存储位置，然后将此位置标识全部标识为 1（未存放数据的位置全部为 0），查询时也是查询对应的位置是否全部为 1，如果全部为 1，**则说明数据是可能存在的，否则一定不存在。**  

**也就是说，如果布隆过滤器说一个元素不在集合中，那么它一定不在这个集合中；但如果它说一个元素在集合中，则有可能是不存在的（存在误差，假阳性）。**
#### 3.1.1 布隆过滤器特征
1. 高效节省空间：布隆过滤器不存储数据本身，只存储数据对应的哈希比特位，因此占用空间非常小。  
2. 快速的插入和查询：插入和查询操作的时间复杂度都为 O(k)，其中 k 为哈希函数的个数，这使得布隆过滤器在处理大量数据时非常高效。
3. 存在假阳性：由于哈希碰撞的可能性，布隆过滤器在判断元素存在时可能会出现误判，即元素实际上不在集合中，但过滤器错误地认为其存在。这种误判率取决于哈希函数的个数和位数组的长度。
4. 不支持删除操作：一旦一个元素被添加到布隆过滤器中，很难将其准确地删除。因为多个元素可能会共用位数组中的某些位，删除一个元素可能会影响其他元素的判断结果。
5. 灵活性与可配置性：布隆过滤器的误判率、位数组的长度和哈希函数的个数都是可以根据具体应用场景进行调整的，以达到最优的性能和误判率平衡。  
#### 3.1.2 布隆过滤器的使用场景
布隆过滤器的主要使用场景有以下几个：
* 大数据量去重：可以用布隆过滤器来进行数据去重，判断一个数据是否已经存在，避免重复插入。
* 防止缓存穿透问题：可以用布隆过滤器来过滤掉恶意请求或请求不存在的数据，避免对后端存储的频繁访问。
* 网络爬虫URL 去重：可以用布隆过滤器来判断 URL 是否已经被爬取，避免重复爬取。 
#### 3.1.2 布隆过滤器的实现
* 分布式布隆过滤器
    * 使用 Redis 4.0 之后提供的插件来实现布隆过滤器。
    * 使用 Redisson 框架实现布隆过滤器。
* 单机布隆过滤器
    * 使用 Google Guava 实现布隆过滤器。
    * 使用 Java 自带的数据结构 BitSet 来实现布隆过滤器。
    * 使用 Hutool 框架实现布隆过滤器。

#### 3.1.3 布隆过滤器发生碰撞
#### 3.1.4 布隆过滤器的扩容   
[扩容机制](## 3.1.4.1 布隆过滤器扩容)
#### 3.1.2 整体的查询流程
    首先数据库中的数据在布隆过滤器初始化的时候就被注册进去了，之后前端发起的每次查询请求，都会先经过布隆过滤器的筛选，如果标识位都为 1 说明数据存在，就去 Redis 里查数据，Redis 有则返回，没有就去数据库中查，将查询结果返回给前端并写入缓存中；    
    若标识位有一个不为 1，那就说明这个数据不存在，如果我们不作任何处理，大量的请求就会被打到数据库上，缓存穿透导致数据库压力过大，严重影响正常业务。所以对于这种不存在的数据，布隆过滤器可以直接把它拦截住，不去数据库中查，而是将错误信息返回给前端。    
### 3.2 缓存击穿解决方式：逻辑过期

### 3.3 缓存雪崩解决方式：ttl

# 4. 秒杀业务，Redission解决库存超卖问题
秒杀业务：
* 秒杀是否开始或结束，如果尚未开始或已经结束，则无法下单
* 库存是否充足，不足则无法下单 
超卖问题是典型的多线程安全问题，针对这一问题的常见解决方案就是加锁： 

## 4.2 超卖问题
### 4.2.1 超卖问题的原因
超卖问题是多线程并发导致的问题（线程不安全），多个线程同时读取库存，发现库存充足，然后各自扣减库存，导致库存扣减超卖。
### 4.2.2 解决库存超卖的方法
解决超卖问题的方法就是加锁，控制线程对共享资源的访问。
* 单机环境下可以使用synchronized关键字、ReentrantLock锁，确保在单机环境中，同一时刻只有一个线程能够执行查询库存和扣减库存的操作，从而避免超卖问题。
* 在分布式场景下就要使用分布式锁（Redission、setnx)
  * 在查询库存和扣减库存之前，先加分布式锁，业务结束之后再释放锁

### 4.2.3 超卖问题+一人一单的整体流程
#### 1）涉及到抢券操作的三张表：
  * tb_voucher: 优惠卷的基本信息，优惠金额、使用规则等。（主键：优惠券的id)
  * tb_seckill_voucher: 优惠券的库存、开始抢购时间、结束抢购时间。（主键：秒杀优惠券的id)
  * tb_voucher_order: 优惠券订单表，记录了下单的用户id、购买的代金卷id （逐渐是用户id和优惠券id)  
#### 2） 场景
解决超卖问题防止优惠券超卖，造成不必要亏损
解决一人一单问题防止某个人重复抢券（避免机器人抢券）
  <!-- * 为了提高秒杀速度，使用redis缓存来记录优惠券的库存，优惠券订单。 -->
#### 2）基本抢券流程 
1. 抢购的优惠券id
2. 根据优惠券id，在数据库中优惠券表查询优惠券的库存是否充足
3. 根据用户id和优惠券id，在优惠券订单表中查询该用户是否购买过这个优惠券
4. 如果优惠券已经购买过，直接退出抢券流程。（不符合一人一单）
5. 如果符合一人一单且库存充足，扣减库存，生成优惠券订单（订单id是全局唯一id)
6. 将订单插入到数据库中
#### 3） 优化
1. Redis优化：使用Redis提高读写速度
   为了快速查找优惠券库存、优惠券订单信息，将秒杀库存和订单信息保存到Redis中，秒杀库存使用String类型保存，订单信息使用Set类型保存。  
   比如，在优惠券表中插入优惠券信息后，再向redis中添加库存信息（以优惠券id作为key，库存作为value)。为了方便校验一人一单，把优惠券订单信息也添加到缓存的set集合中。
2. Lua脚本：将是上述多个redis操作放入Lua脚本，进一步提升服务的性能
    * 减少网络开销，在 Lua脚本 中可以把多个命令放在同一个脚本中运行
    * 原子操作，Redis 会将整个脚本作为一个整体执行，中间不会被其他命令插入（编写脚本过程中无需担心会出现竞态条件）
    * 复用性，客户端发送的脚本会永远存储在 Redis中，意味着其他客户端可以复用这一脚本 
3. 使用Kafka消息队列进行异步解耦
   * 生产者负责判断库存和一人一单，如果满足库存和一人一单要求，保存(用户id,优惠券id)到订单set集合中，（把整个生产者的操作放入lua脚本执行）将（订单id，优惠券id，用户id）作为消息放入到消息队列中。
   * 消费者从消息队列中取出消息，根据订单id，优惠券id，用户id创建订单插入到mysql数据库中。
   * 消费失败： 
 
## 4.3 点赞功能（售卖商品点赞） 
### 4.3.1 数据结构
* 采用Redis的Sorted Set（有序集合）存储商品的总点赞数，存储实时排行榜，确保高性能读写
* 用set存储用户点赞记录
* Mysql的商品表添加一个总点赞数的字段
### 4.3.2 点赞流程
1. 请求传入点赞用户id,点赞商品id
2. 根据用户id和商品id，判断用户是否已经给商品点赞过；如果点赞过，退出点赞流程（保持一人一赞）
    redisTemplate.opsForSet().isMember(userLikeKey, userId)
3. 对商品加redission分布式锁（保证同一时间只有一个用户点赞该商品）
4. 更新Redis: 将sortset中的是商品id的点赞数加1，将点赞记录添加到set集合(检验用户是否点赞）中
5. 更新Mysql: 通过消息队列异步更新Mysql的商品记录的点赞数
### 4.3.3 商品点赞排行榜
1. 请求传入点赞排名数
2. 在sorted set中按照点赞数从高到低获取前N名商品id
3. 根据上述的商品id信息，按序从数据库中查询商品信息，将查询的商品集合返回给用户。

# 10. 消息队列
异步解耦、流量削峰


 # 项目中使用到的设计模式
 
 # 手撕带过期的LRU算法
 # 手撕LFU算法
 # 删除无效的括号（https://leetcode.cn/problems/remove-invalid-parentheses/description/）
 # Kafka


## 3.1.4.1 布隆过滤器扩容 

### **一、传统布隆过滤器无法直接扩容的原因**
1. **固定位数组**：初始化后位数组大小不可变，所有哈希函数基于固定`m`设计。
2. **哈希绑定**：哈希函数的计算依赖于`m`，修改`m`会导致历史元素的哈希位置失效。
3. **元素不可回溯**：布隆过滤器不支持删除操作，无法迁移已插入元素的哈希标记。

---

### **二、扩容的核心思路**
通过 **分层** 或 **动态重建** 的方式扩展容量，同时尽可能复用历史数据。以下是主流扩容方案：

---

#### **方案 1：分层布隆过滤器（Scalable Bloom Filter）**
• **原理**：创建多个独立的布隆过滤器层，每层容量按指数级增长（例如每层容量翻倍）。
  • **初始层**：第一层容量为 `m1`，哈希函数 `k1`。
  • **新增层**：当第一层填充率超过阈值（如50%），创建第二层（容量 `m2 = 2*m1`，哈希函数 `k2 = k1 + 1`），后续层以此类推。
  • **查询逻辑**：查询时从最新层向旧层逐层检查，任意层返回“存在”即判定存在。
• **优点**：
  • 动态扩容无需重建历史层。
  • 总体误判率保持稳定（`P_total ≈ P1 + P2 + ... + Pn`）。
• **缺点**：
  • 内存占用较高（需存储所有层）。
  • 查询时间随层数增加线性增长。

**示例**：  
初始层 `m1=1MB`，误判率 `p1=1%`。当插入元素填满后，新增第二层 `m2=2MB`，误判率 `p2=0.5%`，总误判率约为 `1% + 0.5% = 1.5%`。

---

#### **方案 2：动态重建（Resizable Bloom Filter）**
• **原理**：监控位数组填充率，达到阈值后重建更大的布隆过滤器。
  1. **触发条件**：当位数组中1的比例超过阈值（如70%）时触发扩容。
  2. **新过滤器创建**：按新容量 `m' = 2*m` 创建更大的位数组，并重新设计哈希函数 `k'`。
  3. **数据迁移**：遍历原始数据集，将所有已插入元素重新哈希到新过滤器。
  4. **切换与销毁**：启用新过滤器，逐步淘汰旧过滤器。
• **优点**：内存利用率高，仅维护单个过滤器。
• **缺点**：
  • 迁移成本高（需遍历原始数据集，可能需暂停服务）。
  • 无法处理动态插入场景（迁移期间新元素可能丢失）。

**适用场景**：数据静态或可离线迁移的场景（如爬虫URL去重的历史数据迁移）。

---

#### **方案 3：分片扩容（Sharding）**
• **原理**：将数据分片到多个布隆过滤器，按需扩容分片数量。
  1. 根据数据特征（如哈希前缀）将元素分配到不同分片。
  2. 当某个分片填充率过高时，仅扩容该分片（如分裂为两个子分片）。
• **优点**：扩容粒度细，对性能影响小。
• **缺点**：
  • 分片逻辑需与业务耦合。
  • 查询需遍历所有分片，性能下降。

**示例**：  
使用 `user_id` 的前2位作为分片键，初始分为4个分片。当某个分片容量不足时，将其分裂为2个子分片，总片数变为5。

---

### **三、扩容的技术挑战与优化**
1. **数据迁移效率**：
   • **增量迁移**：在迁移过程中记录新增元素，同时写入新旧两个过滤器。
   • **并行迁移**：使用后台线程异步迁移数据，避免阻塞主流程。

2. **哈希函数一致性**：
   • 分层或分片时，需确保不同层的哈希函数独立且均匀分布，避免误判率叠加失控。

3. **误判率控制**：
   • 分层扩容时，通过公式 `k_i = k_{i-1} + 1` 增加每层的哈希函数数量，抵消因容量翻倍导致的误判率上升。

4. **内存与计算权衡**：
   • 分层方案占用更多内存但扩容平滑；动态重建节省内存但迁移成本高。

---

### **四、替代方案：无需扩容的过滤器**
若业务对扩容敏感，可考虑以下替代数据结构：
1. **布谷鸟过滤器（Cuckoo Filter）**：
   • 支持动态扩容和删除操作，误判率更低。
   • 但实现复杂度高，插入性能可能下降。

2. **可扩展计数布隆过滤器（Counting Bloom Filter）**：
   • 通过计数器支持动态删除和调整容量。
   • 内存开销较大（每个位需4-8位计数器）。
 
---

### **总结**
    布隆过滤器的扩容需权衡 **内存、计算、复杂度** 三方面，核心思路是通过分层、动态重建或分片实现容量扩展。在数据动态增长场景下，分层方案（Scalable Bloom Filter）是最通用和稳定的选择；若数据静态或允许停机迁移，动态重建则更节省资源。最终方案需结合业务需求（实时性、内存限制、误判容忍度）综合决策。